# WordCount-BigData

## 1 hadoop

1. построить Hadoop кластер состоящий из минимум 2 узлов.
    - master узел также должен работать в роли slave
    - на кластере, в виртуальной файловой системе разместить некоторые файлы, протестировать доступ к файлам со всех узлов кластера
    - на кластере запустить пример WordCount, идущий в поставке с Hadoop (hadoop-examples.jar)

2. настроить рабочее окружение и среду разработки для решения MapReduce задач
    - настроить IDE (eclipse, intellij idea)
    - взять WordCount.java из документации Hadoop, настроить проект в IDE, подключить необходимые библиотеки, скомпилировать, собрать .jar
    - запустить пример WordCount с использованием собранного .jar файла

3. рассчитать количество слов в текстах, полученных через проект Gutenberg
    - WordCount, скомпилированный ранее
    - рассчитать для нескольких источников данных (книг)

4. получить 1000 первых наиболее часто используемых слов в тексте (`sort`)
    - отсортировать строки по убыванию частоты слов
    - получить первые 1000 записей из отсортированного набора данных (`limit`)

5. использовать результаты, полученные в предыдущем задании, для построения списка stop-words (предлоги, междометия, союзы и тд). исключить из первых 1000 наиболее часто используемых слов слова из списка stop-words (`filter`, `where`)
    - использовать список stop-words для фильтрации
        + вариант 1: использовать этот список как 'ресурс' для mapreduce задачи -- в этом случае в момент инициализации Mapper'a/Reducer'a необходимо загрузить в память список stop-words из ресурсов
        + вариант 2: использовать несколько источников данных для mapreduce задачи -- в этом случае mapreduce задаче указывать несколько входных источников данных (текст и список слов для фильтрации) 
    - рассчитать для нескольких источников данных (книг)
    - подсказка (можно использовать несколько последовательных map-reduce jobs)

6.`*` для нескольких источников данных рассчитать, какие слова авторы часто используют одновременно (общие часто используемые слова) (`join`)
    - использовать несколько источников данных для одной mapreduce задачи
    - найти пересечение множеств
